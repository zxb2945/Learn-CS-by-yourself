# 吴恩达机器学习系列课程

## 1 Introduction 20210530

### 1.1 Welcome 

### 1.2 What is machine learning 

**Machine learning** algorithms:

**Supervised learning** ：给出正确的答案，让其去模仿

**Unsupervised learning**

Others: Reinforcement learning, recommender learning

### 1.3 Supervised learning

### 1.4 Unsupervised learning



## 2 Linear regression with one variable

### 2.1 Model Represation 20210607

Supervised learning

最常见的就是 classification problem

We have a data set. -> training set

本课程的Notation：

 m= Number of training examples

 x's= input variable / features

 y's= output variable / target variable

弄了个上标表示索引值，不是指幂...

### 2.2 Cost function 20210611

线性回归 Linear regression

> 什么是回归分析呢？这是一个来自统计学的概念。回归分析是指一种预测性的建模技术，主要是研究自变量和因变量的关系。通常使用线/曲线来拟合数据点，然后研究如何使曲线到数据点的距离差异最小。
>
> 线性回归是回归分析的一种。
>
> 1. 假设目标值（因变量）与特征值（自变量）之间线性相关（即满足一个多元一次方程，如：f(x)=w1x1+…+wnxn+b.）。
> 2. 然后构建损失函数。
> 3. 最后通过令损失函数最小来确定参数。（最关键的一步）

最小二乘法

> 误差，当然是真实值与拟合值的差
>
> 而误差平方和
>
> 但为啥要平方（2范数）呢？绝对值（1范数）不可以吗？
>     我们从几何角度来解释这个问题，平方方式的话，则可以视为两点间距离（这里只是没有开方），最小化就是点到直线间距离最短，当然就是垂线

用来拟合数据

Cost function is also called squared error function 

### 2.3 Cost function intuition I

拟合时，最小二乘法公式是个U型函数，最底部就是最好的拟合点。

就是说去拟合的直线称为Hypothesis  : h(x)= a+bx

然后这个最小二乘法就是Cost function : J(b) =...

### 2.4 Cost function intuition II

U型函数只考虑了一个影响变量b，如果考虑两个，即J(a,b), 最后成型的就是三维图像，像一个碗，碗底就是最佳拟合，这个图像被称为contour plots (contour figures)。

进一步思考，我们还可更多J(a,b,c...), 显而易见，之后就很难做可视化处理了。

### 2.5 Gradient descent 20210813

想象J(a,b)所代表的一个三维图像，就像一个起伏的山丘，任选一点，看周围，哪一条路带领你走山丘的最低点，然后就能得到一个局部最低点，多选几个点重复算局部最低点（贪心算法？），得到最优解。

```
a:=b  assignment
a=b   truth assertion
```

> ## 偏导数 Partial derivative
>
> 在一元函数中，导数就是函数的变化率。对于二元函数研究它的“变化率”，由于自变量多了一个，情况就要复杂的多。
>
> 在 xOy 平面内，当动点由 P(x0,y0) 沿不同方向变化时，函数 f(x,y) 的变化快慢一般说来是不同的，因此就需要研究 f(x,y) 在 (x0,y0) 点处沿不同方向的变化率。
>
> 在这里我们只学习函数 f(x,y) 沿着**平行于 x 轴和平行于 y 轴**两个特殊方位变动时， f(x,y) 的变化率。
>
> 偏导数的表示符号为:∂。
>
> 偏导数反映的是函数沿**坐标轴正方向**的变化率
>
> ## 几何意义
>
> 表示固定面上一点的切线斜率。
>
> 偏导数 f’x(x0,y0) 表示固定面上一点对 x 轴的切线斜率；偏导数 f’y(x0,y0) 表示固定面上一点对 y 轴的切线斜率。

### 2.6 Gradient descent intuition

### 2.7 Gradient descent for linear regression

convex function(凸函数)，形象说就是个碗，这就不用担心局部最优解带来的片面性了。



## 3 Linear Algebra review(optional)

### 3.1 Matrices and vectors 20210816

Matrix: 矩阵

Vector: 向量，An n x 1 matrix.

### 3.2 Addition and scalar multiplication

scalar just mean true number. => Matrix和数字相乘

### 3.3 Matrix-vector multiplication

Multiply a matrix by a vector:

m x n 与 n x 1相乘，第一个矩阵的column和第二个向量的row相等是前提，最后得出一个 m x 1的矩阵，降维？

（最后讲了一个预测房子的价格的实例来说明此种运算效率更高，代码更为简洁）？

### 3.4 Matrix-matrix muitiplication 20210820

矩阵为什么叫线性代数：矩阵可以用来计算多个线性方程，大概？

### 3.5 Matrix multiplication properties

矩阵不支持交换律（not commutative）

支持结合律（associative）

Identity matrix : 相当于数字1在乘法中的作用。

### 3.6 Inverse and transpose

在乘法中，1/12与12相乘为Identity number，所以它们inverse.

transpose:   M x N => N x M  转置

（感觉最基础的基础，就很容易理解，至于复杂的证明计算就可以调用相关库函数，所以这么感觉，Linear Algebra就不难，到头来，也就这些知道就行...数学也是站在巨人肩膀上的科目，不必穷尽每个枝干。）



## 4 Linear Regression with multiple variables

### 4.1 Multiple features 20210821

(多元线性回归->multivariate linear regression, 多元线性方程组)

### 4.2 Gradient descent for multiple variables

How to fit parameterof the hypothesis

### 4.3 Gradient descent in practice I: Feature Scaling

scaling -> 缩放

 Feature Scaling不必太精确，它只是让Gradient descent更快下降，收敛的迭代次数更少(converge in a lot fewer iterations)

Mean Normalization : 均值归一化

（不求甚解的心态看一看，了解一下）

### 4.4 Gradient descent in practice II: Learning rate

> 简单的说
> 有极限（极限不为无穷）就是收敛，没有极限（极限为无穷）就是发散。
> 例如：f（x）=1/x 当x趋于无穷是极限为0，所以收敛。
> f（x）= x 当x趋于无穷是极限为无穷，即没有极限，所以发散

Learning rate 形象点可以看成下降的步伐，调大一些，下降快一些。但是过大的话，会导致越过最小值，然后在一个U行中反复横跳，最终无法收敛。

弹幕说有自动调节学习率的算法，先大后小。

### 4.5 Features and polynomial regression 20210822

polynomial -> 多项式

举例来说，一个cost function有两个features：长度和宽度，那你直接可以看成一个feature：面积；

另外，如果是一个三次多项式，比如长度的三次，二次，一次，你可以视为体积，面积，长度三个一次方的features，这就转化为了线性回归。

如上所见，为了拟合数据，定义feature是相对自由的。

### 4.6 Normal equation

Method to solve for 参数 analytically.

相对于Gradient descent的多步迭代，Normal equation类似于二次函数求导为0即为极值来一步到位。

> 解决约束优化问题——拉格朗日乘数法（Lagrange Multiplier Method）
>
> 作为一种优化算法，拉格朗日乘子法主要用于解决约束优化问题，它的基本思想就是通过引入拉格朗日乘子来将含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题。拉格朗日乘子背后的数学意义是其为约束方程梯度线性组合中每个向量的系数。
>
> 　　如何将一个含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题？拉格朗日乘数法从数学意义入手，通过引入拉格朗日乘子建立极值条件，对n个变量分别求偏导对应了n个方程，然后加上k个约束条件（对应k个拉格朗日乘子）一起构成包含了（n+k）变量的（n+k）个方程的方程组问题，这样就能根据求方程组的方法对其进行求解。
> ————————————————
> 版权声明：本文为CSDN博主「-柚子皮-」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
> 原文链接：https://blog.csdn.net/pipisorry/article/details/52135854

### 4.7 Normal equation and non-invertibility(optional)

non-invertibility -> 不可逆性



## 5 Octave Tutorial 20210825

### 5.1 Basic operations

现在多用Python甚于Octave.

> **NumPy是一个关于矩阵运算的库**，熟悉Matlab的都应该清楚，这个库就是让python能够进行矩阵话的操作，而不用去写循环操作。
>
> numpy包含两种基本的数据类型：数组和矩阵。
>
> ```python
> #创建矩阵
> >>> m=mat([1,2,3])
> >>> m
> matrix([[1, 2, 3]])
> 
> #取值
> >>> m[0]                #取一行
> matrix([[1, 2, 3]])
> >>> m[0,1]              #第一行，第2个数据
> 2
> >>> m[0][1]             #注意不能像数组那样取值了
> Traceback (most recent call last):
>   File "<stdin>", line 1, in <module>
>   ...
> IndexError: index 1 is out of bounds for axis 0 with size 1
> 
> #将Python的列表转换成NumPy的矩阵
> >>> list=[1,2,3]
> >>> mat(list)
> matrix([[1, 2, 3]])
> 
> #矩阵相乘
> >>> m1=mat([1,2,3])     #1行3列
> >>> m2=mat([4,5,6]) 
> >>> m1*m2.T             #注意左列与右行相等 m2.T为转置操作
> matrix([[32]])       
> >>> multiply(m1,m2)     #执行点乘操作，要使用函数，特别注意
> matrix([[ 4, 10, 18]])  
> 
> #排序
> >>> m=mat([[2,5,1],[4,6,2]])    #创建2行3列矩阵
> >>> m
> matrix([[2, 5, 1],
>         [4, 6, 2]])
> >>> m.sort()                    #对每一行进行排序
> >>> m
> matrix([[1, 2, 5],
>         [2, 4, 6]])
> ————————————————
> 版权声明：本文为CSDN博主「yqtaowhu」的原创文章，遵循CC 4.0 BY-SA版权协议，
> 转载请附上原文出处链接及本声明。
> 原文链接：https://blog.csdn.net/taoyanqi8932/article/details/52703686
> ```



## 6 Logistic Regression 20210829

### 6.1 Classification

说明了用linear regression用于分类问题不是 a good idea.

Logistic Regression is actually a classification algorithm. (不要被它的名字弄confused，只是historical reasons)

### 6.2 Hypothesis Representation 

Logistic function让函数收敛到0到1之间。

### 6.3 Decision Boundary

The decision boundary is a property not of the training set, but of the hypothesis and of the parameters. So long as we've given my parameter vector, that defines the decision boundary.

这个decision boundary可视化的话，可以是坐标系一条划分positive features和negative features的直线，也可以是圆，并不一定。

### 6.4 Cost Function

注意 Hypothesis Representation 与 cost function的区别！前者是去拟合数据的，后者是基于最小二乘法基础上去修正前者的，如果预测值错误，要给出cost penalty.

### 6.5 Simplified cost function and gradient descent

### 6.6 Advanced optimization

介绍了gradient descent之外的一些方法来minimize the cost function.

实现细节只有专家清楚，把库拿来用就行。

### 6.7 Multi-class classification: One-vs-all

之前都是binary classification problem.

"one versus rest"



## 7 Regularization 20210904

### 7.1 The problem of overfitting 

过度拟合，高阶函数振荡，七转八弯

### 7.2 Cost Function

不是直接扔掉高阶项features，而是在cost function中加上高阶项features的平方来进行penalizing，从而尽可能弱化高阶项特征。

### 7.3 Regularized linear regression

### 7.4 Regularized logstic regression



## 8 Neural Networks: Representation

### 8.1 Non-linear hypothesis 20210905

所谓的神经网络

识别汽车图像需要上百万个features，这对于基于logistic regression上的classifier来说，hypothesis representation的polynomial term会无比复杂，并不现实。

### 8.2 Neurons and the brain

神经元

### 8.3 Model representation I

最简单的计算单元，两层：input layer和output layer，就是features和parameters的矩阵乘积而来的多项式。

多层的神经网络的话，中间的就被称为hidden layer.

### 8.4 Model representation II 20210910

最简单的两层神经网络就等同于Logistic Regression，多层的神经网络也可以看成features由隐藏层计算而来的Logistic Regression.  理解这个计算过程的Forward Propagation.

### 8.5 Examples and intuitions I

用来拟合非线性分类问题

How single nuerons in a nueral network can be used to compute logical function.

就是神经元函数怎么去模拟逻辑上的AND和OR.

### 8.6 Examples and intuitions II

同样可以实现NOT，用神经元函数实现输入1，输出0.

最后举例一个识别手写数字的神经网络，每一层神经网络通过提取features层层递进使成像更为清晰，最终被Logistic Regression Classifies识别出来。

### 8.7 Multi-class classfication

把output layer搞成多个输出口。



## 9 Neural Networks: Learning

### 9.1 Cost function 20210912

神经网络的cost function基本上就是一般化Logistic regression的cost function.

### 9.2 Backpropagation algorithm

顾名思义，就是从out layer开始计算误差，然后依次往回推到input layer.

这个算法是用来求解上一节的cost function. 看起来步骤繁多，相当复杂，如果编程实现，你都没法理解基本设计...

### 9.3 Backpropagation intuition

对神经网络的数学模型，先有一个training set，挑取两个input值，肯定可以越过数学模型先确定output值，然后通过数学模型计算output值（最后最终输出函数跟logistic regression一样是sigmoid函数），这两个output值之间一开始肯定有相当大的误差，这时候就要调图上层与层之间的权重了。那么如何求这个权重就是backpropagation algorithm的作用了，从输出层往后推，各种求偏导，计算每个权重对结果误差的影响，反复迭代，最后得出基于training set的数学模型。

### 9.4 Implementation note: Unrolling parameter

advanced optimization

相对于logistic regression，神经网络的参数不是向量，而是matrices。

### 9.5 Gradient checking 20210920

用backpropagation推出来的cost function可能有bug，这时候需要用一种近似方法去验证，也是涉及求导，然而对于两者求导的细节不甚清楚，所以也就云里雾里... 后者应该跟之前提到的gradient descent有关联。(identical)

拉格朗日中值定理：连续可导函数，通过求一段区域的平均值来近拟其中一点的导数。

backpropagation算法 相对 gradient decent算法而言，对于计算机计算量小很多，所以后者一般只用来验证一次前者有没有bug，然后就关闭掉。

### 9.6 Random initialization

开始学习前，神经网络初始的参数matrices也是有要求的...

### 9.7 Putting it together

对于一个neural architecture而言，一开始要选择default的各项数据，比如hidden layer，普遍来说就一层。如果是多层的情况，那么每一层的hidden unites数应该相同。（在数学之美中也提到，神经网络相对贝叶斯网络而言，模型标准建构上更为完善）

Training a neural network:

1. Randomly initialize weights.
2. Implement forward propagation to get f(x) for any x.
3. Implement code to computer cost function J(...).
4. Implement backprop to compute partial derivatives of J(...).
5. Use gradient checking to compare J(...) computed using backpropagation vs. using numerical estimate of gradient of J(...). Then disable gradient checking code.
6. Use gradient descent or advanced optimization method with backpropagation to try to minimize J(...).

以上6看来，9.5节就理解错误了... gradient descent不是和backpropagation同个级别的概念，而是说，backpro用来计算cost function，然后gradient descent基于backpro的计算结果来引导优化backpro计算迭代的方向。

 backpropagation跟linear regression和 logistic regression算是同一个级别的概念，而gradient descent是用来优化这些算法的。

### 9.8 Autonomous driving example

展示了一段1992年的训练视频...



## 10 Advice for applying maching learning

### 10.1 Decide what to try next 20210922

training set不是越多越好，要把时间用在刀刃上

### 10.2 Evaluating a hypothesis

按7：3讲data set分成training set和test set.

用来防止overfitting.

### 10.3 Model selection

polynomial的次数选择上，最简单的就是一次的linear regression.

关于model selection, 就是基于training set来minimize各个次数的polynomial model, 一般来说都能minimize的一个相同的误差(不是的，次数越高误差越小，然而会存在overfitting问题)，然后再依次用test set去验证，选取一个表现较好的model.

但是以上选择还是不够generalization，对于从未见过的数据呢？

另一种分法：按6：2：2将data set分成training set, cross validation set, test set.

相应可以定义 training set error, cross validation set error, test set error.

cross validation set用来select model, 而test set用来estimate generalization error.

### 10.4 Diagnosis bias vs. variance

随着order增大，training set error 越来越小， 而cross validation error 会是一个U型，两端误差很大，分别是underfit 和 overfit 问题导致的。

high **Bias** problem：low order polynomial 导致的underfit 问题；

high **Variance** problem：high order polynomial 导致的overfit 问题.

> 偏差：度量了学习算法的期望预期与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。把模型比喻成一支猎枪，预测的目标是靶心，假设射手不会手抖且视力正常，那么这支枪(模型)的能力就可以用多次射击后的中心(相当于预测值的期望，即和靶心的距离来衡量(偏离了靶心有多远)。当猎枪(模型)和子弹(样本)质量都很好时，就能得到方差和偏差都比较低的结果。但是如果猎枪是没有校准的或者目标超出有效射程，那么偏差就会更高(击中点离靶心比较远)。子弹(样本)也可能出问题，比如子弹的形状、重量等因素，导致瞄准一个点多次射击在靶上会散开一片，这就是高方差的情况。
>
> 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，反映了在不同样本集上模型输出值的变异性，方差的大小反应了样本在总体数据中的代表性，或者说不同样本下模型预测的稳定性。即刻画了数据扰动所造成的的影响。比如现在要通过一些用户属性去预测其消费能力，结果有两个样本，一个样本中大多数都是高等级活跃会员，另一个则是大部分是低质量用户，两个样本预测出来的数据的差异就非常大，也就是模型在两个样本上的方差很大。如果模型在多个样本下的训练误差(经验损失)“抖动”比较厉害，则有可能是样本有问题。
>
> 噪声：表达了在当前任务上学习算法所能达到的期望泛化误差的下界（即模型学习的上限），即刻画了学习问题本身的难度。不可控的错误很难避免，这被称为不可约偏差(irreducible error)，即噪声无法通过模型来消除。噪声通常是出现在“数据采集”的过程中的，且具有随机性和不可控性，比如采集用户数据的时候仪器产生的随机性偏差、或者在实验中受到其他不可控因素的干扰等。
>
> low bias and low variance：又准又稳
> low bias and high variance： 准但不稳
> high bias and low variance：不准但稳
> high bias and high variance：不准又不稳
>
> ————————————————
> 版权声明：本文为CSDN博主「bigdata老司机」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
> 原文链接：https://blog.csdn.net/yawei_liu1688/article/details/107790461

### 10.5 Regularization and bias/variance 20210925

不是直接扔掉高阶项features，而是在cost function中加上高阶项features的平方来进行penalizing，从而尽可能弱化高阶项特征。

=>对上面这句话的理解：cost function里加上高阶项features的平方的总和，会导致如果这个总和值大的话，cost function就会变大，所以拟合模型的时候要尽量去减小这些features值，高阶项features值变小的话，就会避免overfitting的问题，这就是所谓的regularization.

因为以上关系：Bias/variance as a function of the regularizatiom parameter lambda.

### 10.6 Learning curves

error与training set size 相关的曲线，前者分为 training ser error和 cross validation error,  high bias和high variance的这个learning curves都有相关特点，由此可以判断 if a learning algorithm are suffering high bias or hign variance.

### 10.7 Revisited















